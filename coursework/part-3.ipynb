{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee8d307-1818-4d3e-86c7-8d3873393b5b",
   "metadata": {},
   "source": [
    "# Part 3: Peer-to-peer Message Behaviour Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a89661-48f9-433d-9ac3-00f94b220e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c58e9-c1bb-471e-8d7e-5ebcf36c750d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install Python packages (pip only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c433636-63e8-45ac-91ab-df4598e50d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g., %pip install some-package\n",
    "%pip install networkx\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install scipy\n",
    "%pip install pandas\n",
    "%pip install operator\n",
    "%pip install ndlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a98e79-7408-4b7e-9937-f0611b21dc21",
   "metadata": {},
   "source": [
    "### Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b645ed-b469-45e6-ba5b-1c70e7efd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g., import some-package\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.CompositeModel as gc\n",
    "import ndlib.models.compartments as cs\n",
    "from ndlib.utils import multi_runs\n",
    "from ndlib.viz.mpl.DiffusionTrend import DiffusionTrend\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e292c7-df21-4fe9-b720-c21acdd2ceb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db29460-d751-47b9-a597-7f466a9e7f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1 of 2\n",
    "\n",
    "Examine the file \"p2p_msg_cmt224.csv\" which represents messaging behaviour between users on a messaging platform. Each row has four columns, representing a single event where a person (person_a) messaged another person (person_b) on some date (date) at some time of day (time). From this, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77652a-85fa-4fe6-b7e6-d95827082ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Q1. Build a suitable network to represent social connections based on the messaging behaviour that took place in the first 28 days. In doing so, assume that one or more messages from one person to another represents a mutual underlying social connection (i.e., regardless of whether person_a messaged person_b, person_b messaged person_a, or both at some point). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fae4d-a6b8-4c71-aaba-1dfaff94252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE:\n",
    "# 1 读取文件并存储信息\n",
    "data_path = 'p2p_msg_cmt224.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "# 2 通过时间和日期进行排序\n",
    "data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'])\n",
    "data.sort_values('datetime', inplace=True)\n",
    "print(data.head(20))\n",
    "# 3 获取最小的时间和日期作为起始点，获取28天内的所有数据\n",
    "start = data['datetime'].min()\n",
    "end = start + pd.Timedelta(days=28)\n",
    "data_in_range = data[(data['datetime'] >= start) & (data['datetime'] < end)]\n",
    "print(len(data_in_range))\n",
    "print(data_in_range.iloc[-1])\n",
    "# 4 将这些在28天范围内的数据建立无向图\n",
    "G = nx.from_pandas_edgelist(data_in_range, 'person_a', 'person_b', create_using=nx.Graph())\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "# 5 可视化网络\n",
    "plt.figure(figsize=(12, 12))\n",
    "nx.draw(G, with_labels=True, node_size=20, font_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5d080d0-8837-4605-8926-50eb6bd7d020",
   "metadata": {},
   "source": [
    "ANSWER: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a76d52-6471-4695-826c-788e3078fab9",
   "metadata": {},
   "source": [
    "##### Q2. Using the largest connected component of the network constructed in Task 1, Q1. What is the mean, median and the standard deviation of the differences between the maximum degree of separation of each individual and the average distance between the individual and all others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1808c52-538f-4461-b8be-5adc186a3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE:\n",
    "# 1 计算图的最大连通组件,并建立子图\n",
    "largest_connected_component = max(nx.connected_components(G), key=len)\n",
    "lcc_subgraph = G.subgraph(largest_connected_component)\n",
    "# 2 对于每个节点\n",
    "# (1) 最大分离度：计算该节点到最远节点的最短路径长度\n",
    "# (2) 平均距离：计算该节点的平均路径长度：该节点到其他所有节点的平均路径长度\n",
    "# (3) 计算差值，存到列表\n",
    "differences = []\n",
    "for node in lcc_subgraph.nodes():\n",
    "    # 计算该节点到所有节点的最短路径长度\n",
    "    all_path_length = nx.single_source_shortest_path_length(lcc_subgraph, node)\n",
    "    path_length_list = list(all_path_length.values())\n",
    "    if all_path_length:\n",
    "        max_sparation = np.max(path_length_list)\n",
    "        average_distance = np.mean(path_length_list)\n",
    "        differences.append(np.abs(max_sparation - average_distance))\n",
    "# 3 计算列表中所有数据的均值、中位数、标准差\n",
    "mean_difference = np.mean(differences)\n",
    "median_difference = np.median(differences)\n",
    "std_difference = np.std(differences)\n",
    "print(f\"The mean of difference: {mean_difference:.2f}\")\n",
    "print(f\"The median of difference: {median_difference:.2f}\")\n",
    "print(f\"The standard deviation of difference: {std_difference:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed938505-3426-4965-8e5b-7a63119f710b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ANSWER: \n",
    "The mean of difference: 2.24\n",
    "The median of difference: 2.23\n",
    "The standard deviation of difference: 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0743d-26e7-48b8-9f54-569ce6818ea9",
   "metadata": {},
   "source": [
    "##### Q3. Build another suitable network to represent social connections based on ALL message behaviour in the dataset. In doing so, assume that one or messages from one person to another represents a MUTUAL underlying social connection (i.e., regardless of whether person_a messaged person_b, person_b messaged person_a, or both at some point).Can the social phenomenon, ‘Triadic Closure’, be supported for the common nodes that exist in both the network created from behaviour for the first 28 days (i.e., from Task 1, Q1) and the network built from all message behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df320c0-3d4f-4217-a8eb-49263693d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE:\n",
    "# 假设列名为 'person_a' 和 'person_b'，若不是请根据上面的输出进行修改\n",
    "# 构建全数据集的网络\n",
    "G_full = nx.from_pandas_edgelist(data, 'person_a', 'person_b', create_using=nx.Graph())\n",
    "\n",
    "# 假设G是之前构建的基于首28天的网络\n",
    "# 找出两个网络共有的节点\n",
    "common_nodes = set(G.nodes()).intersection(set(G_full.nodes()))\n",
    "\n",
    "# 对共有节点创建子图\n",
    "subgraph_28 = G.subgraph(common_nodes)\n",
    "subgraph_full = G_full.subgraph(common_nodes)\n",
    "\n",
    "# 计算三元闭包系数\n",
    "triadic_closure_28 = nx.transitivity(subgraph_28)\n",
    "triadic_closure_full = nx.transitivity(subgraph_full)\n",
    "\n",
    "# 输出三元闭包系数\n",
    "print(f\"首28天网络的三元闭包系数: {triadic_closure_28:.2f}\")\n",
    "print(f\"完整数据集网络的三元闭包系数: {triadic_closure_full:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bbb165a-b6b5-4e2f-9d2e-976867a4902b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ANSWER: \n",
    "首28天网络的三元闭包系数: 0.05\n",
    "完整数据集网络的三元闭包系数: 0.07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c69305-9297-4f3f-8248-537c45bb605e",
   "metadata": {},
   "source": [
    "##### Q4. What hypothetical, non-existent edges would need to be added to the network representing all message behaviour (i.e., from Task 1, Q3) such that a message could pass along a path from any node to any other? In doing so, aim to minimise the number of edges that would be needed as well as the longest shortest path in the network as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93070886-bcfc-4b6e-846f-a25720c850ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE:\n",
    "\"\"\"\n",
    "all_cc = list(nx.connected_components(G_full))\n",
    "# 贪心算法连接所有连通分量试图得到最小直径的图\n",
    "# 直到只剩一个连通分量也就是整个图全连通后停止\n",
    "while len(all_cc) > 1:\n",
    "    best_edges = (-1, -1)\n",
    "    the_longest_shortest_path = float('inf')\n",
    "    for i in range(len(all_cc)):\n",
    "        for j in range(i + 1, len(all_cc)):\n",
    "            # 建立测试图\n",
    "            test_graph = nx.Graph(G_full)\n",
    "            # 连接边来测试\n",
    "            test_graph.add_edge(next(iter(all_cc[i])), next(iter(all_cc[j])))\n",
    "            # 计算连接该边后图的最大连通组件的最长最短路径\n",
    "            lcc = max(nx.connected_components(test_graph), key=len)\n",
    "            # 建立最大连通组件的子图\n",
    "            subgraph = test_graph.subgraph(lcc)\n",
    "            # 求子图直径\n",
    "            test_longest_shortest_path = nx.diameter(subgraph)\n",
    "            # 贪心\n",
    "            if test_longest_shortest_path < the_longest_shortest_path:\n",
    "                the_longest_shortest_path = test_longest_shortest_path\n",
    "                best_edges = (i, j)\n",
    "    # 连接直径最小化的两个连通分量\n",
    "    i, j = best_edges\n",
    "    G_full.add_edge(next(iter(all_cc[i])), next(iter(all_cc[j])))\n",
    "    new_component = all_cc[i].union(all_cc[j])\n",
    "    all_cc = [c for k, c in enumerate(all_cc) if k not in (i, j)]\n",
    "    all_cc.append(new_component)\n",
    "# 计算优化后的网络直径\n",
    "if nx.is_connected(G_full):\n",
    "    print(\"New diameter:\", nx.diameter(G_full))\n",
    "else:\n",
    "    print(\"Graph is still not connected.\")\n",
    "\"\"\"\n",
    "components = list(nx.connected_components(G_full))\n",
    "subgraphs = [G_full.subgraph(c).copy() for c in components]\n",
    "\n",
    "# 计算每个子图的多个中心性指标\n",
    "centrality_measures = []\n",
    "for sg in subgraphs:\n",
    "    centrality = {}\n",
    "    centrality['betweenness'] = nx.betweenness_centrality(sg)\n",
    "    centrality['closeness'] = nx.closeness_centrality(sg)\n",
    "    centrality['degree_centrality'] = nx.degree_centrality(sg)\n",
    "    centrality_measures.append(centrality)\n",
    "\n",
    "# 选择每个连通分量的代表节点\n",
    "rep_nodes = []\n",
    "for idx, sg in enumerate(subgraphs):\n",
    "    # 综合考虑多个中心性指标\n",
    "    combined_score = {node: centrality_measures[idx]['betweenness'][node] * 0.4 +\n",
    "                             centrality_measures[idx]['closeness'][node] * 0.3 +\n",
    "                             centrality_measures[idx]['degree_centrality'][node] * 0.3\n",
    "                      for node in sg.nodes()}\n",
    "    # 选择综合得分最高的节点\n",
    "    best_node = max(combined_score, key=combined_score.get)\n",
    "    rep_nodes.append(best_node)\n",
    "\n",
    "# 连接这些代表节点\n",
    "new_edges = [(rep_nodes[i], rep_nodes[i+1]) for i in range(len(rep_nodes)-1)]\n",
    "G_full.add_edges_from(new_edges)\n",
    "print(new_edges)\n",
    "\n",
    "# 检查新图的连通性和尝试计算新的直径\n",
    "if nx.is_connected(G_full):\n",
    "    print(\"New diameter after connecting components:\", nx.diameter(G_full))\n",
    "else:\n",
    "    print(\"Still not fully connected.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d58ae102-2739-4063-a39a-d2c58c3204c6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ANSWER: \n",
    "贪心：13min4.8s 优化后的网络直径为: 9\n",
    "三个指标：10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa92191-51cc-4f9d-966c-b8cd5de3d80d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 2 of 2 \n",
    "\n",
    "Using the largest connected component of the network constructed from all data in Task 1, Q2, assume the role of an outsider with complete visibility of the network that now wishes to spread a hypothetical message such that everyone in the component would know the information it contained as quickly as possible. Assume that messages will now spread in sequential timesteps using the following mechanism. If an individual is told the message at timestep 𝑡, the individual will forward the message to all of their direct connections at timestep 𝑡+1. Individuals can therefore be told the message more than once. From this, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e447d7-e1a4-40d7-a4af-a7e4f6c2a214",
   "metadata": {},
   "source": [
    "##### Q1. If you could only select 1 individual to tell at timestep 0, what set of nodes could you select from which would result in the message being received by everyone in the fewest timesteps as possible and what would the number of timesteps be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea9640-98fd-4cf6-948c-ea57db8d82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE:\n",
    "# 选出一个节点，使得从该节点传播，最短时间传播到网络中的所有人\n",
    "# 选初始点指标，紧密中心性，建立紧密中心性从大到小序列\n",
    "closeness_centrality = sorted(\n",
    "    [(node[0], node[1]) for node in nx.closeness_centrality(lcc_subgraph).items()], \n",
    "    key=operator.itemgetter(1), \n",
    "    reverse=True\n",
    ")\n",
    "# 输出前五个\n",
    "for node, centrality in closeness_centrality[:10]:\n",
    "    print(f\"Node: {node}   Closeness Centrality: {centrality:.2f}\")\n",
    "\n",
    "# 函数：传播模型\n",
    "def runSIModelOnANetwork(G, rate, iterations, initial_infected=None, fraction_infected=None, model_seed=1):\n",
    "    # 传播模型\n",
    "    model = ep.SIModel(G, seed=model_seed)\n",
    "\n",
    "    # 配置模型\n",
    "    # 创建模型配置项\n",
    "    model_configuration = mc.Configuration()\n",
    "    # 设置一个节点将信息告知其连接/邻居的几率\n",
    "    model_configuration.add_model_parameter('beta', rate) # Probability between 0..1 (0..100%)\n",
    "    # 对模型执行n次迭代来模拟传播，并存储结果\n",
    "    if initial_infected is not None:\n",
    "        model_configuration.add_model_initial_configuration(\"Infected\", initial_infected)\n",
    "    else:\n",
    "        model_configuration.add_model_parameter(\"fraction_infected\", fraction_infected)\n",
    "    model.set_initial_status(model_configuration)\n",
    "    iterations = model.iteration_bunch(iterations)\n",
    "    return model, iterations\n",
    "\n",
    "# 函数：评估模型\n",
    "def evaluateModel(network, model, iterations, threshold):\n",
    "    \n",
    "    # 绘制传播曲线\n",
    "    trends = model.build_trends(iterations)\n",
    "    viz = DiffusionTrend(model, trends)\n",
    "    viz.plot()\n",
    "\n",
    "    # 输出传播动态\n",
    "    results = calculate_iterations_to_reach_threshold(\n",
    "        trends,\n",
    "        network.number_of_nodes(),\n",
    "        threshold,\n",
    "        True\n",
    "    )\n",
    "    print(f\"Threshold met = {results[0][0]} after {results[0][1]} iterations from the initial iteration\")\n",
    "\n",
    "# 输出传播动态\n",
    "def calculate_iterations_to_reach_threshold(trends, number_of_nodes, threshold, verbose=False):\n",
    "    threshold_as_number_of_nodes = (number_of_nodes*threshold)\n",
    "    iteration_counts_per_simulation = []\n",
    "    for simulation in trends:\n",
    "        number_infected_per_iteration = simulation[\"trends\"][\"node_count\"][1]\n",
    "        threshold_met = False\n",
    "        iteration_count = 0\n",
    "        for iteration, number_infected in enumerate(number_infected_per_iteration):\n",
    "            if verbose:\n",
    "                print(f\"Iteration: {iteration}    Number infected: {number_infected}    ({(number_infected / number_of_nodes)})\")\n",
    "            if number_infected < threshold_as_number_of_nodes:\n",
    "                iteration_count += 1\n",
    "            else:\n",
    "                threshold_met = True\n",
    "                break\n",
    "        iteration_counts_per_simulation.append((threshold_met, iteration_count))\n",
    "    return iteration_counts_per_simulation\n",
    "\n",
    "# 运行\n",
    "network = lcc_subgraph\n",
    "information_spreading_rate = 1\n",
    "number_of_iterations = 10\n",
    "initial_infected_node = closeness_centrality[0]\n",
    "eva_threshold = 1.0\n",
    "\n",
    "model, interations = runSIModelOnANetwork(\n",
    "    network,\n",
    "    information_spreading_rate,\n",
    "    number_of_iterations,\n",
    "    initial_infected=initial_infected_node\n",
    ")\n",
    "evaluateModel(\n",
    "    network,\n",
    "    model,\n",
    "    interations,\n",
    "    eva_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f20f5387-43e7-4846-923e-bc0c3a9055dd",
   "metadata": {},
   "source": [
    "ANSWER: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161ea1f-f955-49fd-b612-64dfa50adf6e",
   "metadata": {},
   "source": [
    "##### Q2. If you had to select any 5 individuals to tell at timestep 0, can the message be received by everyone in fewer timesteps than the single individual selection in Q1? In determining your answer, use one or more appropriate network connectivity measures, rather than an exhaustive search through every combination of nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d85c4-4cf4-4444-b091-166f70ca6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE:\n",
    "# 运行\n",
    "network = lcc_subgraph\n",
    "information_spreading_rate = 1\n",
    "number_of_iterations = 10\n",
    "initial_infected_node = [node[0] for node in closeness_centrality[:5]]\n",
    "eva_threshold = 1.0\n",
    "\n",
    "model, interations = runSIModelOnANetwork(\n",
    "    network,\n",
    "    information_spreading_rate,\n",
    "    number_of_iterations,\n",
    "    initial_infected=initial_infected_node\n",
    ")\n",
    "evaluateModel(\n",
    "    network,\n",
    "    model,\n",
    "    interations,\n",
    "    eva_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4945b93d-5b7b-451b-8496-f90e3405d544",
   "metadata": {},
   "source": [
    "ANSWER: \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
